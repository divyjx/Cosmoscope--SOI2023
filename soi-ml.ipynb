{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:21:55.602223Z","iopub.execute_input":"2023-07-09T10:21:55.602611Z","iopub.status.idle":"2023-07-09T10:21:55.614149Z","shell.execute_reply.started":"2023-07-09T10:21:55.602581Z","shell.execute_reply":"2023-07-09T10:21:55.613011Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/mars-spec-train/train_labels.csv\n/kaggle/input/mars-spec-train/train_features/S0459.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1. Loading data and libraries ","metadata":{}},{"cell_type":"code","source":"# for processing numbers and files csv\nimport pandas as pd\nimport numpy as np\n\n# for visualization\n# import matplotlib.pyplot as plt\nimport seaborn as sns\n# %matplotlib inline\n\n# preprocessing \n# from scipy.fft import fft\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# model related\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\nimport tensorflow as tf\n# other\nimport copy\n# from scipy.signal import find_peaks\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:28:46.011431Z","iopub.execute_input":"2023-07-09T10:28:46.011874Z","iopub.status.idle":"2023-07-09T10:28:46.019039Z","shell.execute_reply.started":"2023-07-09T10:28:46.011824Z","shell.execute_reply":"2023-07-09T10:28:46.017823Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# A. Data description\n###  input data \n<ul> \n<li>there are 1000 training examples</li>\n<li>each of them is dataframe with time, mass , and intensity:: sorted by time then mass</li>\n<li>dataframe lenghts are variable</li>\n</ul>\n\n### output binary clssification\n<ul> \n<li>positive class probability</li>\n</ul>\n\n\n# B. Feature Extraction Steps\n<ul>\n<li>group mass values upto 1 decimal (0.0 to 650.0 , diff = 0.5)           /<br>-- total (1300) or multiply by 2  and take round() </li>\n<li>take time values and fill remaining with (0.00 to 53.00 , diff = 0.02) /<br>-- total (2650) or multiply by 50 and take round() </li>\n<li>create a Time X Mass matrix (2650,1300) with intensity values</li>\n\n<li>noramlize intensity values --\n    <ol> \n    <li>subtract mean</li>\n    <li>minmax scale</li>\n    </ol>   \n</li>\n<li>total 2650x1300 values = 3,445,000</li> \n</ul>\n\n# C. Model architecture\n<ul>\n<li>feed this as convolutional layers (2,5 2d conv stride 2, 5 , that is comvolute these values)  . This will group similar time and mass values</li>\n<li>feed this as pooling layers ( pooling layers with mean/ max pooling ) </li>\n<li>further data reduction steps</li>\n<li>then fully connected layers</li>\n<li>sigmoid or softmax layer</li>\n<li>output positive label probability</li>\n</ul>\n","metadata":{}},{"cell_type":"code","source":"metadata = pd.read_csv('/kaggle/input/mars-spec-train/metadata.csv').fillna(0)\ntrain_labels = pd.read_csv('/kaggle/input/mars-spec-train/train_labels.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:26:52.919833Z","iopub.execute_input":"2023-07-09T10:26:52.920997Z","iopub.status.idle":"2023-07-09T10:26:52.937535Z","shell.execute_reply.started":"2023-07-09T10:26:52.920960Z","shell.execute_reply":"2023-07-09T10:26:52.936228Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"metadata.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:26:53.110018Z","iopub.execute_input":"2023-07-09T10:26:53.110440Z","iopub.status.idle":"2023-07-09T10:26:53.124679Z","shell.execute_reply.started":"2023-07-09T10:26:53.110406Z","shell.execute_reply":"2023-07-09T10:26:53.123431Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"  sample_id  split  derivatized             features_path  \\\n0     S0000  train          0.0  train_features/S0000.csv   \n1     S0001  train          0.0  train_features/S0001.csv   \n\n                  features_md5_hash  \n0  52ec6d6f8372500ab4e069b5fbdae6f9  \n1  348f90baed8a8189bf0d4c7b9ed9f965  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>split</th>\n      <th>derivatized</th>\n      <th>features_path</th>\n      <th>features_md5_hash</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>S0000</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>train_features/S0000.csv</td>\n      <td>52ec6d6f8372500ab4e069b5fbdae6f9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>S0001</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>train_features/S0001.csv</td>\n      <td>348f90baed8a8189bf0d4c7b9ed9f965</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_labels.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:26:53.547538Z","iopub.execute_input":"2023-07-09T10:26:53.547915Z","iopub.status.idle":"2023-07-09T10:26:53.560879Z","shell.execute_reply.started":"2023-07-09T10:26:53.547886Z","shell.execute_reply":"2023-07-09T10:26:53.560174Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"  sample_id  aromatic  hydrocarbon  carboxylic_acid  \\\n0     S0000         0            0                0   \n1     S0001         0            0                0   \n\n   nitrogen_bearing_compound  chlorine_bearing_compound  \\\n0                          0                          0   \n1                          0                          0   \n\n   sulfur_bearing_compound  alcohol  other_oxygen_bearing_compound  mineral  \n0                        0        0                              0        1  \n1                        0        0                              0        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>aromatic</th>\n      <th>hydrocarbon</th>\n      <th>carboxylic_acid</th>\n      <th>nitrogen_bearing_compound</th>\n      <th>chlorine_bearing_compound</th>\n      <th>sulfur_bearing_compound</th>\n      <th>alcohol</th>\n      <th>other_oxygen_bearing_compound</th>\n      <th>mineral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>S0000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>S0001</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2. Preprocessing, Feature extraction","metadata":{}},{"cell_type":"code","source":"# constants\nnum_mass_values = 1350\nnum_time_values = 2650\nmatrix_shape = (num_time_values, num_mass_values)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:26:54.961524Z","iopub.execute_input":"2023-07-09T10:26:54.962145Z","iopub.status.idle":"2023-07-09T10:26:54.966082Z","shell.execute_reply.started":"2023-07-09T10:26:54.962100Z","shell.execute_reply":"2023-07-09T10:26:54.965138Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\n# Function to create the Time X Mass matrix for a single data sample\ndef create_matrix(id ):\n    \n    sample_id, split, derivate, path, _ = metadata.iloc[id]\n#     print(path)\n    path = '/kaggle/input/mars-spec-train/'+ path\n    data = pd.read_csv(path)\n\n    label = None\n    if (split == 'train'):\n        label = train_labels.iloc[id].values[1:]\n\n    # discretization of time and mass\n    data.time = (data.time*50).round()\n    data.mass = (data.mass*2).round()\n    data.time = data.time.astype(int)\n    data.mass = data.mass.astype(int)\n    \n    # scaling intensity\n    data.intensity = MinMaxScaler().fit_transform(data.intensity.values.reshape(-1, 1))\n    \n    # filling matrix\n    matrix = np.zeros(matrix_shape)\n    matrix[data['time'],data['mass']] = data['intensity']\n\n    return matrix , label\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:27:01.238587Z","iopub.execute_input":"2023-07-09T10:27:01.239001Z","iopub.status.idle":"2023-07-09T10:27:01.248338Z","shell.execute_reply.started":"2023-07-09T10:27:01.238968Z","shell.execute_reply":"2023-07-09T10:27:01.247313Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sample_matrix, sample_label= create_matrix(np.random.randint(809)) ## 0.2 second # max = 1120\nsample_matrix[0:100, 100:200],sample_label\n# print(sample_matrix[500:1000,np.random.randint(0,100)])","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:27:11.187866Z","iopub.execute_input":"2023-07-09T10:27:11.188958Z","iopub.status.idle":"2023-07-09T10:27:11.916509Z","shell.execute_reply.started":"2023-07-09T10:27:11.188912Z","shell.execute_reply":"2023-07-09T10:27:11.915438Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n        [1.51311344e-03, 0.00000000e+00, 1.90530988e-03, ...,\n         0.00000000e+00, 1.38614912e-04, 0.00000000e+00],\n        ...,\n        [8.18333545e-04, 0.00000000e+00, 3.81971991e-04, ...,\n         0.00000000e+00, 5.88868141e-05, 0.00000000e+00],\n        [1.04290932e-03, 0.00000000e+00, 3.50740247e-04, ...,\n         0.00000000e+00, 4.32898068e-05, 0.00000000e+00],\n        [1.21561581e-03, 0.00000000e+00, 3.84363984e-04, ...,\n         0.00000000e+00, 3.81134415e-05, 0.00000000e+00]]),\n array([0, 0, 1, 1, 0, 1, 1, 0, 0], dtype=object))"},"metadata":{}}]},{"cell_type":"markdown","source":"Dummy model","metadata":{}},{"cell_type":"code","source":"training_data = range(809)  # Load your training data\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:27:28.850301Z","iopub.execute_input":"2023-07-09T10:27:28.850678Z","iopub.status.idle":"2023-07-09T10:27:28.856401Z","shell.execute_reply.started":"2023-07-09T10:27:28.850651Z","shell.execute_reply":"2023-07-09T10:27:28.855013Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    \n    def __init__(self, data, batch_size):\n        self.data = data\n        self.batch_size = batch_size\n    def __len__(self):\n        return len(self.data) // self.batch_size\n\n    def __getitem__(self, idx):        \n        \n        low = idx * self.batch_size\n        high = min(low + self.batch_size, len(self.data))\n        batch_x = []\n        batch_y = []\n\n        for i,data_sample in enumerate(self.data[low:high]):\n            processed_sample, processed_label = self.preprocess_data(data_sample)\n            batch_x.append(processed_sample)\n            batch_y.append(processed_label)\n        return np.array(batch_x), np.array(batch_y)\n\n    def preprocess_data(self, data_sample):\n        # Perform the feature extraction steps and create the matrix\n        matrix, label = create_matrix(data_sample)\n        if type(label) == np.ndarray:\n            label = np.array(label).astype(int)\n        return matrix , label\n    \n    def getLabel(self, data_sample):\n        matrix, label = create_matrix(data_sample)\n        if type(label) == np.ndarray:\n            label = np.array(label).astype(int)\n        return label\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:27:32.349001Z","iopub.execute_input":"2023-07-09T10:27:32.349420Z","iopub.status.idle":"2023-07-09T10:27:32.360532Z","shell.execute_reply.started":"2023-07-09T10:27:32.349388Z","shell.execute_reply":"2023-07-09T10:27:32.359443Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train_data, val_data = train_test_split(training_data, test_size=0.2, random_state=42)\ntrain_labels.iloc[[3,334,534]].values[:,1:].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:27:34.429343Z","iopub.execute_input":"2023-07-09T10:27:34.429766Z","iopub.status.idle":"2023-07-09T10:27:34.443031Z","shell.execute_reply.started":"2023-07-09T10:27:34.429734Z","shell.execute_reply":"2023-07-09T10:27:34.441674Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\nmodel = Sequential()\n\nmodel.add(Conv2D(1, kernel_size=(5, 4),strides = (4,2), activation='relu', input_shape=(2650, 1350, 1)))\nmodel.add(MaxPooling2D(pool_size=(100, 1), strides=(40,1)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(16, activation='relu'))\n\nmodel.add(Dense(9, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Define the batch size and number of epochs\nbatch_size = 16\nnum_epochs = 20\n\n# Create instances of the custom data generator for training and validation\ntrain_data_generator = DataGenerator(train_data, batch_size)\nval_data_generator = DataGenerator(val_data, batch_size)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:38:31.883066Z","iopub.execute_input":"2023-07-09T10:38:31.883503Z","iopub.status.idle":"2023-07-09T10:38:31.987155Z","shell.execute_reply.started":"2023-07-09T10:38:31.883472Z","shell.execute_reply":"2023-07-09T10:38:31.985998Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_6 (Conv2D)           (None, 662, 674, 1)       21        \n                                                                 \n max_pooling2d_6 (MaxPooling  (None, 15, 674, 1)       0         \n 2D)                                                             \n                                                                 \n flatten_2 (Flatten)         (None, 10110)             0         \n                                                                 \n dense_6 (Dense)             (None, 16)                161776    \n                                                                 \n dense_7 (Dense)             (None, 9)                 153       \n                                                                 \n=================================================================\nTotal params: 161,950\nTrainable params: 161,950\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor = 'loss', patience = 3 )\n\nhistory = model.fit(train_data_generator, epochs=num_epochs, validation_data=val_data_generator, callbacks=[es])","metadata":{"execution":{"iopub.status.busy":"2023-07-09T10:38:43.028470Z","iopub.execute_input":"2023-07-09T10:38:43.028899Z","iopub.status.idle":"2023-07-09T12:29:11.067186Z","shell.execute_reply.started":"2023-07-09T10:38:43.028864Z","shell.execute_reply":"2023-07-09T12:29:11.063528Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Epoch 1/20\n40/40 [==============================] - 355s 9s/step - loss: 0.5025 - accuracy: 0.1781 - val_loss: 0.3192 - val_accuracy: 0.0250\nEpoch 2/20\n40/40 [==============================] - 294s 7s/step - loss: 0.3227 - accuracy: 0.2797 - val_loss: 0.2816 - val_accuracy: 0.2875\nEpoch 3/20\n40/40 [==============================] - 282s 7s/step - loss: 0.2968 - accuracy: 0.3250 - val_loss: 0.2660 - val_accuracy: 0.3750\nEpoch 4/20\n40/40 [==============================] - 331s 8s/step - loss: 0.2820 - accuracy: 0.3438 - val_loss: 0.2553 - val_accuracy: 0.3812\nEpoch 5/20\n40/40 [==============================] - 292s 7s/step - loss: 0.2607 - accuracy: 0.3750 - val_loss: 0.2354 - val_accuracy: 0.3688\nEpoch 6/20\n40/40 [==============================] - 307s 8s/step - loss: 0.2417 - accuracy: 0.3969 - val_loss: 0.2198 - val_accuracy: 0.3750\nEpoch 7/20\n40/40 [==============================] - 270s 7s/step - loss: 0.2217 - accuracy: 0.4125 - val_loss: 0.2111 - val_accuracy: 0.3812\nEpoch 8/20\n40/40 [==============================] - 363s 9s/step - loss: 0.2094 - accuracy: 0.4281 - val_loss: 0.2058 - val_accuracy: 0.4000\nEpoch 9/20\n40/40 [==============================] - 299s 7s/step - loss: 0.2025 - accuracy: 0.4375 - val_loss: 0.2008 - val_accuracy: 0.4125\nEpoch 10/20\n40/40 [==============================] - 339s 8s/step - loss: 0.1900 - accuracy: 0.4531 - val_loss: 0.1952 - val_accuracy: 0.4125\nEpoch 11/20\n40/40 [==============================] - 287s 7s/step - loss: 0.1837 - accuracy: 0.4469 - val_loss: 0.1932 - val_accuracy: 0.4187\nEpoch 12/20\n40/40 [==============================] - 338s 8s/step - loss: 0.1778 - accuracy: 0.4719 - val_loss: 0.1905 - val_accuracy: 0.4187\nEpoch 13/20\n40/40 [==============================] - 315s 8s/step - loss: 0.1716 - accuracy: 0.4656 - val_loss: 0.1847 - val_accuracy: 0.4313\nEpoch 14/20\n40/40 [==============================] - 310s 8s/step - loss: 0.1683 - accuracy: 0.4609 - val_loss: 0.1836 - val_accuracy: 0.4250\nEpoch 15/20\n40/40 [==============================] - 321s 8s/step - loss: 0.1623 - accuracy: 0.4578 - val_loss: 0.1822 - val_accuracy: 0.4437\nEpoch 16/20\n40/40 [==============================] - 307s 8s/step - loss: 0.1588 - accuracy: 0.4641 - val_loss: 0.1837 - val_accuracy: 0.4437\nEpoch 17/20\n40/40 [==============================] - 325s 8s/step - loss: 0.1552 - accuracy: 0.4578 - val_loss: 0.1772 - val_accuracy: 0.4563\nEpoch 18/20\n40/40 [==============================] - 309s 8s/step - loss: 0.1506 - accuracy: 0.4578 - val_loss: 0.1763 - val_accuracy: 0.4563\nEpoch 19/20\n40/40 [==============================] - 341s 9s/step - loss: 0.1482 - accuracy: 0.4781 - val_loss: 0.1737 - val_accuracy: 0.4375\nEpoch 20/20\n40/40 [==============================] - 308s 8s/step - loss: 0.1426 - accuracy: 0.4703 - val_loss: 0.1722 - val_accuracy: 0.4437\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = ...  # Get model (Sequential, Functional Model, or Model subclass)\nmodel.save('model.keras')\n# metadata.to_csv(\"opopo\")","metadata":{"execution":{"iopub.status.busy":"2023-07-09T12:29:11.074260Z","iopub.execute_input":"2023-07-09T12:29:11.074719Z","iopub.status.idle":"2023-07-09T12:29:11.233561Z","shell.execute_reply.started":"2023-07-09T12:29:11.074658Z","shell.execute_reply":"2023-07-09T12:29:11.232462Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"train_loss = 0\ntrain_lab = []\ntrain_pred = []\nfrom sklearn.metrics import log_loss\nfor i,data in enumerate(train_data):\n    mat , lab = create_matrix(data)\n    lab = np.array(lab).astype(int).reshape(1,9)\n    pred = model.predict(mat.reshape(-1,2650,1350,1), verbose = 0)\n    train_lab.append(lab)\n    train_pred.append(pred)\n    if (i%100 == 0):\n        print (i)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:34:23.276374Z","iopub.execute_input":"2023-07-09T13:34:23.276848Z","iopub.status.idle":"2023-07-09T13:38:38.316261Z","shell.execute_reply.started":"2023-07-09T13:34:23.276814Z","shell.execute_reply":"2023-07-09T13:38:38.315198Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"0\n100\n200\n300\n400\n500\n600\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntrain_lab = np.array(train_lab).reshape(-1,9)\ntrain_pred = np.array(train_pred).reshape(-1,9)\nprint(f\"train log loss : {log_loss(train_lab, train_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:43:34.438178Z","iopub.execute_input":"2023-07-09T13:43:34.439276Z","iopub.status.idle":"2023-07-09T13:43:34.449437Z","shell.execute_reply.started":"2023-07-09T13:43:34.439236Z","shell.execute_reply":"2023-07-09T13:43:34.447964Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"train log loss : 1.0316461173431106\n","output_type":"stream"}]},{"cell_type":"code","source":"val_loss = 0\nval_lab = []\nval_pred = []\nfrom sklearn.metrics import log_loss\nfor i,data in enumerate(val_data):\n    mat , lab = create_matrix(data)\n    lab = np.array(lab).astype(int).reshape(1,9)\n    pred = model.predict(mat.reshape(-1,2650,1350,1), verbose = 0)\n    val_lab.append(lab)\n    val_pred.append(pred)\n    if (i%100 == 0):\n        print (i)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:44:41.002741Z","iopub.execute_input":"2023-07-09T13:44:41.003271Z","iopub.status.idle":"2023-07-09T13:46:00.874609Z","shell.execute_reply.started":"2023-07-09T13:44:41.003235Z","shell.execute_reply":"2023-07-09T13:46:00.873144Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"0\n100\n","output_type":"stream"}]},{"cell_type":"code","source":"val_lab = np.array(val_lab).reshape(-1,9)\nval_pred = np.array(val_pred).reshape(-1,9)\nprint(f\"train log loss : {log_loss(val_lab, val_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:46:31.807227Z","iopub.execute_input":"2023-07-09T13:46:31.807768Z","iopub.status.idle":"2023-07-09T13:46:31.822980Z","shell.execute_reply.started":"2023-07-09T13:46:31.807735Z","shell.execute_reply":"2023-07-09T13:46:31.821804Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"train log loss : 1.0560311513842007\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"valid log loss : {log_loss(val_lab, val_pred).mean()}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:46:31.959468Z","iopub.execute_input":"2023-07-09T13:46:31.959913Z","iopub.status.idle":"2023-07-09T13:46:31.969568Z","shell.execute_reply.started":"2023-07-09T13:46:31.959877Z","shell.execute_reply":"2023-07-09T13:46:31.968075Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"valid log loss : 1.0560311513842007\n","output_type":"stream"}]},{"cell_type":"markdown","source":"train log loss : 1.0316461173431106 \\\nvalid log loss : 1.0560311513842007 \\\nsample predictions below","metadata":{}},{"cell_type":"code","source":"for i in range (10):\n    sample_matrix, sample_label= create_matrix(np.random.randint(809)) ## 0.2 second # max = 1120\n    print (f\"{i+1}th prediction\")\n    print(\"prediction : \",(model.predict(sample_matrix.reshape(-1, 2650,1350,1),verbose = 0).round().astype(int)).squeeze())\n    print(\"true label : \",np.array(sample_label))","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:53:29.115517Z","iopub.execute_input":"2023-07-09T13:53:29.115973Z","iopub.status.idle":"2023-07-09T13:53:33.497884Z","shell.execute_reply.started":"2023-07-09T13:53:29.115936Z","shell.execute_reply":"2023-07-09T13:53:33.496613Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"1th prediction\nprediction :  [0 0 0 0 0 0 0 0 0]\ntrue label :  [0 0 0 0 0 0 0 0 0]\n2th prediction\nprediction :  [0 1 0 0 0 0 0 0 0]\ntrue label :  [0 1 0 0 0 0 0 0 0]\n3th prediction\nprediction :  [1 0 1 1 0 0 0 0 0]\ntrue label :  [1 0 1 1 0 0 0 0 0]\n4th prediction\nprediction :  [0 1 0 0 0 0 0 0 0]\ntrue label :  [0 1 0 0 0 0 0 0 0]\n5th prediction\nprediction :  [0 1 0 0 0 0 0 0 0]\ntrue label :  [0 1 0 0 0 0 0 0 0]\n6th prediction\nprediction :  [0 0 0 0 0 0 0 0 0]\ntrue label :  [0 0 0 0 0 0 0 0 0]\n7th prediction\nprediction :  [0 1 0 0 0 0 0 0 0]\ntrue label :  [0 1 0 0 0 0 0 0 0]\n8th prediction\nprediction :  [0 0 0 0 0 0 0 0 0]\ntrue label :  [0 0 0 0 0 0 0 0 0]\n9th prediction\nprediction :  [1 0 1 0 0 0 0 0 0]\ntrue label :  [1 0 1 0 0 0 0 0 0]\n10th prediction\nprediction :  [0 0 0 0 0 0 0 0 1]\ntrue label :  [0 0 0 0 0 0 0 0 1]\n","output_type":"stream"}]}]}