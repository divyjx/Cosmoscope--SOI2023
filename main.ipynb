{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.read_csv(\"./metadata.csv\")\n",
    "data_info = data_info.fillna(0)\n",
    "# data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample S0000 - first sample\n",
    "data_info_train = data_info.loc[data_info.split=='train']\n",
    "data_info_test = data_info.loc[data_info.split=='val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"TRAIN\", data_info_train.describe(), \"\\n\\nTEST\",data_info_test.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data (labeled)\n",
    "Train data 809 rows  \\\n",
    "We have to split this into two parts (train and valid) \n",
    "# Test  Data (predict)\n",
    "Test  data 312 rows  -- we have to predict this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = pd.read_csv('./train_labels.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the break down of label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output                                              0    1         \n",
      "\n",
      "aromatic                                           [730  79]\n",
      "hydrocarbon                                        [544 265]\n",
      "carboxylic_acid                                    [694 115]\n",
      "nitrogen_bearing_compound                          [713  96]\n",
      "chlorine_bearing_compound                          [791  18]\n",
      "sulfur_bearing_compound                            [778  31]\n",
      "alcohol                                            [783  26]\n",
      "other_oxygen_bearing_compound                      [788  21]\n",
      "mineral                                            [692 117]\n"
     ]
    }
   ],
   "source": [
    "print(\"output\".ljust(50) , \" 0\".ljust(5), \"1\".ljust(10))\n",
    "print()\n",
    "for cols in data_label.columns[1:]:\n",
    "    print(str(cols).ljust(50) , np.array(data_label[cols].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot([1, 2, 3, 4], [1, 4, 9, 16])\n",
    "# ysdf = 0\n",
    "cols = list(data_info.columns)\n",
    "cols.remove('features_md5_hash')\n",
    "cols\n",
    "label_names = ['sample_id', 'aromatic', 'hydrocarbon', 'carboxylic_acid',\n",
    "       'nitrogen_bearing_compound', 'chlorine_bearing_compound',\n",
    "       'sulfur_bearing_compound', 'alcohol', 'other_oxygen_bearing_compound',\n",
    "       'mineral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>split</th>\n",
       "      <th>derivatized</th>\n",
       "      <th>features_path</th>\n",
       "      <th>features_md5_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0000</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_features/S0000.csv</td>\n",
       "      <td>52ec6d6f8372500ab4e069b5fbdae6f9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0001</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_features/S0001.csv</td>\n",
       "      <td>348f90baed8a8189bf0d4c7b9ed9f965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0002</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train_features/S0002.csv</td>\n",
       "      <td>4686ad9bc3716966f63b6ff83d1d8324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0003</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_features/S0003.csv</td>\n",
       "      <td>de6b53605c5887967dc3661a3a711c2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_features/S0004.csv</td>\n",
       "      <td>fbfd90092d10d15a5d6919327ddde2ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>S1116</td>\n",
       "      <td>val</td>\n",
       "      <td>1.0</td>\n",
       "      <td>val_features/S1116.csv</td>\n",
       "      <td>86a7ab7517b69448fd6eb6f518670c5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>S1117</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_features/S1117.csv</td>\n",
       "      <td>82ad1a2c511290193697b4dc6baa131e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>S1118</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_features/S1118.csv</td>\n",
       "      <td>2125667ba387f06d20e644f2a612c8a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>S1119</td>\n",
       "      <td>val</td>\n",
       "      <td>1.0</td>\n",
       "      <td>val_features/S1119.csv</td>\n",
       "      <td>d8f27d84c0bf0a888ebf7cbb4f832624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>S1120</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_features/S1120.csv</td>\n",
       "      <td>6bed4722f14301197d499fc9c0a969ba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_id  split  derivatized             features_path  \\\n",
       "0        S0000  train          0.0  train_features/S0000.csv   \n",
       "1        S0001  train          0.0  train_features/S0001.csv   \n",
       "2        S0002  train          1.0  train_features/S0002.csv   \n",
       "3        S0003  train          0.0  train_features/S0003.csv   \n",
       "4        S0004  train          0.0  train_features/S0004.csv   \n",
       "...        ...    ...          ...                       ...   \n",
       "1116     S1116    val          1.0    val_features/S1116.csv   \n",
       "1117     S1117    val          0.0    val_features/S1117.csv   \n",
       "1118     S1118    val          0.0    val_features/S1118.csv   \n",
       "1119     S1119    val          1.0    val_features/S1119.csv   \n",
       "1120     S1120    val          0.0    val_features/S1120.csv   \n",
       "\n",
       "                     features_md5_hash  \n",
       "0     52ec6d6f8372500ab4e069b5fbdae6f9  \n",
       "1     348f90baed8a8189bf0d4c7b9ed9f965  \n",
       "2     4686ad9bc3716966f63b6ff83d1d8324  \n",
       "3     de6b53605c5887967dc3661a3a711c2b  \n",
       "4     fbfd90092d10d15a5d6919327ddde2ab  \n",
       "...                                ...  \n",
       "1116  86a7ab7517b69448fd6eb6f518670c5b  \n",
       "1117  82ad1a2c511290193697b4dc6baa131e  \n",
       "1118  2125667ba387f06d20e644f2a612c8a0  \n",
       "1119  d8f27d84c0bf0a888ebf7cbb4f832624  \n",
       "1120  6bed4722f14301197d499fc9c0a969ba  \n",
       "\n",
       "[1121 rows x 5 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_info\u001b[39m.\u001b[39;49miloc[\u001b[39mlen\u001b[39;49m(data_info)]\n\u001b[0;32m      2\u001b[0m \u001b[39m# data_info.iloc[0]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1656\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1653\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1655\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1656\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[0;32m   1658\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1587\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1588\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1589\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1121"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_length = 300 ## extracting these many values from data set\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "test = []\n",
    "\n",
    "for i in range(0,len(data_info)):\n",
    "    sample_id, split, derivatized, path = data_info[cols].iloc[i]\n",
    "    if split == 'train':\n",
    "        label = data_label.iloc[i][1:]\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    df = data\n",
    "    data_length = len(df)\n",
    "    batch_size = data_length // feature_length\n",
    "\n",
    "    # Initialize lists to store the batch features\n",
    "    mean_time = []\n",
    "    mean_mass = []\n",
    "    mean_intensity = []\n",
    "\n",
    "    features = []\n",
    "    # Iterate over the batches\n",
    "    for i in range(feature_length):\n",
    "        # Calculate the start and end indices of the current batch\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "\n",
    "        # Extract the current batch from the dataset\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "\n",
    "        # Calculate the mean of time, mass, and intensity for the current batch\n",
    "        mean_time.append(batch['time'].mean())\n",
    "        mean_mass.append(batch['mass'].mean())\n",
    "        mean_intensity.append(batch['intensity'].mean())\n",
    "    features = mean_mass + mean_time + mean_intensity\n",
    "    features.append(derivatized)\n",
    "    if split == 'train':\n",
    "        X.append(copy.deepcopy(features))\n",
    "        y.append(label)\n",
    "    else:\n",
    "        test.append(copy.deepcopy(features))\n",
    "\n",
    "    #for data visualization\n",
    "\n",
    "    # Combine the batch features into a single dataframe\n",
    "    # batch_features = pd.DataFrame({\n",
    "    #     'mean_time': mean_time,\n",
    "    #     'mean_mass': mean_mass,\n",
    "    #     'mean_intensity': mean_intensity\n",
    "    # })\n",
    "\n",
    "\n",
    "    # plt.scatter(batch_features['mean_mass'] ,batch_features['mean_intensity'],s = 2 )\n",
    "    # # plt.xlim(1,70)\n",
    "    # plt.ylim(1,2e7)\n",
    "    # plt.show()\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sns.lineplot(data = df, x= 'time', y = 'intensity')\n",
    "X_np = np.array(copy.deepcopy(X)).astype(float)\n",
    "y_np = np.array(copy.deepcopy(y)).astype(float)\n",
    "test_np = np.array(copy.deepcopy(test)).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X : (809, 901)\n",
      "shape of y : (809, 9)\n",
      "shape of test : (312, 901)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of X : {X_np.shape}\\n\"+\n",
    "      f\"shape of y : {y_np.shape}\\n\"+\n",
    "      f\"shape of test : {test_np.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X_np)\n",
    "df_y = pd.DataFrame(y_np)\n",
    "df_test = pd.DataFrame(test_np)\n",
    "\n",
    "#saving to csv\n",
    "df_X.to_csv(\"df_X.csv\")\n",
    "df_y.to_csv(\"df_y.csv\")\n",
    "df_test.to_csv(\"df_test.csv\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nan data \n",
    "-- no nan rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols_x = [col for col in df_test if df_X[col].isna().any()]   \n",
    "nan_cols_test = [col for col in df_test if df_X[col].isna().any()]   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing \n",
    "standand scaler\n",
    "minmax scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(data_label.columns[1:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       roc -  65    mse -  17    positive percentage -  9\n",
      "hydrocarbon                    roc -  73    mse -  27    positive percentage -  32\n",
      "carboxylic_acid                roc -  61    mse -  27    positive percentage -  14\n",
      "nitrogen_bearing_compound      roc -  71    mse -  17    positive percentage -  11\n",
      "chlorine_bearing_compound      roc -  48    mse -  7    positive percentage -  2\n",
      "sulfur_bearing_compound        roc -  60    mse -  10    positive percentage -  3\n",
      "alcohol                        roc -  55    mse -  10    positive percentage -  3\n",
      "other_oxygen_bearing_compound  roc -  67    mse -  6    positive percentage -  2\n",
      "mineral                        roc -  72    mse -  17    positive percentage -  14\n"
     ]
    }
   ],
   "source": [
    "# unscaled data using logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.33, random_state=42)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict_proba(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    print(cols.ljust(30,\" \"),\n",
    "        \"roc - \",math.ceil(roc_auc_score(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   mse - \",math.ceil(mean_squared_error(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   positive percentage - \", pos)\n",
    "\n",
    "# results are variable for different types\n",
    "# for random_state in [10 ,239,3,94023,234,342,234]:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.33, random_state=random_state)\n",
    "#     for i,cols in enumerate(classes):\n",
    "#         if (i==0):\n",
    "#             continue\n",
    "#         model = LogisticRegression(max_iter = 1000000)\n",
    "#         model.fit(X_train, y_train[:,i])\n",
    "#         preds = model.predict_proba(X_test)\n",
    "#         print(str(random_state).ljust(10,\" \"),cols.ljust(50,\" \"),roc_auc_score(y_test[:,i], preds[:, 1]))\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_np_minmax = scaler.fit_transform(X_np) \n",
    "test_np_minmax = scaler.transform(test_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       roc -  86    mse -  8    positive percentage -  9\n",
      "hydrocarbon                    roc -  87    mse -  14    positive percentage -  32\n",
      "carboxylic_acid                roc -  94    mse -  9    positive percentage -  14\n",
      "nitrogen_bearing_compound      roc -  93    mse -  8    positive percentage -  11\n",
      "chlorine_bearing_compound      roc -  98    mse -  3    positive percentage -  2\n",
      "sulfur_bearing_compound        roc -  90    mse -  3    positive percentage -  3\n",
      "alcohol                        roc -  93    mse -  3    positive percentage -  3\n",
      "other_oxygen_bearing_compound  roc -  90    mse -  3    positive percentage -  2\n",
      "mineral                        roc -  81    mse -  9    positive percentage -  14\n"
     ]
    }
   ],
   "source": [
    "#min max scaled input\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np_minmax, y_np, test_size=0.33, random_state=42)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict_proba(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    print(cols.ljust(30,\" \"),\n",
    "        \"roc - \",math.ceil(roc_auc_score(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   mse - \",math.ceil(mean_squared_error(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   positive percentage - \", pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X_np_std = std_scaler.fit_transform(X_np) \n",
    "test_np_std = std_scaler.transform(test_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       roc -  75    mse -  9    positive percentage -  9\n",
      "hydrocarbon                    roc -  83    mse -  18    positive percentage -  32\n",
      "carboxylic_acid                roc -  91    mse -  11    positive percentage -  14\n",
      "nitrogen_bearing_compound      roc -  91    mse -  10    positive percentage -  11\n",
      "chlorine_bearing_compound      roc -  98    mse -  3    positive percentage -  2\n",
      "sulfur_bearing_compound        roc -  83    mse -  3    positive percentage -  3\n",
      "alcohol                        roc -  92    mse -  4    positive percentage -  3\n",
      "other_oxygen_bearing_compound  roc -  86    mse -  4    positive percentage -  2\n",
      "mineral                        roc -  76    mse -  12    positive percentage -  14\n"
     ]
    }
   ],
   "source": [
    "# standard scaled input\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np_std, y_np, test_size=0.33, random_state=42)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict_proba(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    print(cols.ljust(30,\" \"),\n",
    "        \"roc - \",math.ceil(roc_auc_score(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   mse - \",math.ceil(mean_squared_error(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   positive percentage - \", pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = \"\"\"               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.90      1.00      0.95       239\n",
    "         1.0       \"\"\"\n",
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       positive accuarcy 0.40\n",
      "hydrocarbon                    positive accuarcy 0.77\n",
      "carboxylic_acid                positive accuarcy 0.53\n",
      "nitrogen_bearing_compound      positive accuarcy 0.44\n",
      "chlorine_bearing_compound      positive accuarcy 0.00\n",
      "sulfur_bearing_compound        positive accuarcy 0.50\n",
      "alcohol                        positive accuarcy 1.00\n",
      "other_oxygen_bearing_compound  positive accuarcy 1.00\n",
      "mineral                        positive accuarcy 0.79\n"
     ]
    }
   ],
   "source": [
    "# for low positive compunds the algorithm performs worst and result is highly variable with random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np_minmax, y_np, test_size=0.33, random_state=43)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    # print(cols,'\\n', classification_report(y_test[:,i], preds))\n",
    "    print(cols.ljust(30,\" \"),'positive accuarcy', classification_report(y_test[:,i], preds,zero_division=True)[len(ts)-1:len(ts)+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       positive accuarcy 0.38 9\n",
      "aromatic                       positive accuarcy 0.62 9\n",
      "aromatic                       positive accuarcy 0.30 9\n",
      "aromatic                       positive accuarcy 0.80 9\n",
      "aromatic                       positive accuarcy 0.67 9\n",
      "aromatic                       positive accuarcy 0.40 9\n",
      "aromatic                       positive accuarcy 0.80 9\n",
      "aromatic                       positive accuarcy 0.33 9\n",
      "aromatic                       positive accuarcy 0.50 9\n",
      "aromatic                       positive accuarcy 0.44 9\n",
      "aromatic                       positive accuarcy 0.44 9\n",
      "aromatic                       positive accuarcy 0.62 9\n",
      "aromatic                       positive accuarcy 0.75 9\n",
      "aromatic                       positive accuarcy 0.50 9\n"
     ]
    }
   ],
   "source": [
    "# reasult is \n",
    "sel_cols = \"aromatic\"\n",
    "for rs in [231,3123,12,3,123,32,3,13,1000000,1010010,1232,32313,45362,562456]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np_minmax, y_np, test_size=0.33, random_state=rs)\n",
    "    for i,cols in enumerate(classes):\n",
    "        if (cols!=sel_cols):\n",
    "            continue\n",
    "        model = LogisticRegression(max_iter = 1000000)\n",
    "        model.fit(X_train, y_train[:,i])\n",
    "        preds = model.predict(X_test)\n",
    "        pos = int(100*y_np[:,i].sum()/809)\n",
    "        # print(cols,'\\n', classification_report(y_test[:,i], preds))\n",
    "        print(cols.ljust(30,\" \"),'positive accuarcy', classification_report(y_test[:,i], preds,zero_division=True)[len(ts)-1:len(ts)+3],pos)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "\n",
    "model = Sequential()  \n",
    "model.add(Dense(512, activation = 'relu', input_shape = (1,901)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
