{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import copy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.read_csv(\"./metadata.csv\")\n",
    "data_info = data_info.fillna(0)\n",
    "# data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample S0000 - first sample\n",
    "data_info_train = data_info.loc[data_info.split=='train']\n",
    "data_info_test = data_info.loc[data_info.split=='val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = pd.read_csv('./train_labels.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the label count of label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output                                              0    1         \n",
      "\n",
      "aromatic                                           [730  79]\n",
      "hydrocarbon                                        [544 265]\n",
      "carboxylic_acid                                    [694 115]\n",
      "nitrogen_bearing_compound                          [713  96]\n",
      "chlorine_bearing_compound                          [791  18]\n",
      "sulfur_bearing_compound                            [778  31]\n",
      "alcohol                                            [783  26]\n",
      "other_oxygen_bearing_compound                      [788  21]\n",
      "mineral                                            [692 117]\n"
     ]
    }
   ],
   "source": [
    "print(\"output\".ljust(50) , \" 0\".ljust(5), \"1\".ljust(10))\n",
    "print()\n",
    "for cols in data_label.columns[1:]:\n",
    "    print(str(cols).ljust(50) , np.array(data_label[cols].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot([1, 2, 3, 4], [1, 4, 9, 16])\n",
    "# ysdf = 0\n",
    "cols = list(data_info.columns)\n",
    "cols.remove('features_md5_hash')\n",
    "cols\n",
    "label_names = ['sample_id', 'aromatic', 'hydrocarbon', 'carboxylic_acid',\n",
    "       'nitrogen_bearing_compound', 'chlorine_bearing_compound',\n",
    "       'sulfur_bearing_compound', 'alcohol', 'other_oxygen_bearing_compound',\n",
    "       'mineral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1121"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction from dataset\n",
    "taking segments of dataset and appling mean to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_length = 300 ## extracting these many values from a data set entry\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "test = []\n",
    "\n",
    "for i in range(0,len(data_info)):\n",
    "    sample_id, split, derivatized, path = data_info[cols].iloc[i]\n",
    "    if split == 'train':\n",
    "        label = data_label.iloc[i][1:]\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    df = data\n",
    "    data_length = len(df)\n",
    "    batch_size = data_length // feature_length\n",
    "\n",
    "    # Initialize lists to store the batch features\n",
    "    mean_time = []\n",
    "    mean_mass = []\n",
    "    mean_intensity = []\n",
    "\n",
    "    features = []\n",
    "    # Iterate over the batches\n",
    "    for i in range(feature_length):\n",
    "        # Calculate the start and end indices of the current batch\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "\n",
    "        # Extract the current batch from the dataset\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "\n",
    "        # Calculate the mean of time, mass, and intensity for the current batch\n",
    "        mean_time.append(batch['time'].mean())\n",
    "        mean_mass.append(batch['mass'].mean())\n",
    "        mean_intensity.append(batch['intensity'].mean())\n",
    "    features = mean_mass + mean_time + mean_intensity\n",
    "    features.append(derivatized)\n",
    "    if split == 'train':\n",
    "        X.append(copy.deepcopy(features))\n",
    "        y.append(label)\n",
    "    else:\n",
    "        test.append(copy.deepcopy(features))\n",
    "\n",
    "    #for data visualization\n",
    "\n",
    "    # Combine the batch features into a single dataframe\n",
    "    # batch_features = pd.DataFrame({\n",
    "    #     'mean_time': mean_time,\n",
    "    #     'mean_mass': mean_mass,\n",
    "    #     'mean_intensity': mean_intensity\n",
    "    # })\n",
    "\n",
    "\n",
    "    # plt.scatter(batch_features['mean_mass'] ,batch_features['mean_intensity'],s = 2 )\n",
    "    # # plt.xlim(1,70)\n",
    "    # plt.ylim(1,2e7)\n",
    "    # plt.show()\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sns.lineplot(data = df, x= 'time', y = 'intensity')\n",
    "X_np = np.array(copy.deepcopy(X)).astype(float)\n",
    "y_np = np.array(copy.deepcopy(y)).astype(float)\n",
    "test_np = np.array(copy.deepcopy(test)).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X : (809, 901)\n",
      "shape of y : (809, 9)\n",
      "shape of test : (312, 901)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of X : {X_np.shape}\\n\"+\n",
    "      f\"shape of y : {y_np.shape}\\n\"+\n",
    "      f\"shape of test : {test_np.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X_np)\n",
    "df_y = pd.DataFrame(y_np)\n",
    "df_test = pd.DataFrame(test_np)\n",
    "\n",
    "#saving to csv\n",
    "df_X.to_csv(\"df_X.csv\")\n",
    "df_y.to_csv(\"df_y.csv\")\n",
    "df_test.to_csv(\"df_test.csv\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nan data \n",
    "-- no nan rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols_x = [col for col in df_test if df_X[col].isna().any()]   \n",
    "nan_cols_test = [col for col in df_test if df_X[col].isna().any()]   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Testing\n",
    "standand scaler\n",
    "minmax scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(data_label.columns[1:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       roc -  65    mse -  17    positive percentage -  9\n",
      "hydrocarbon                    roc -  73    mse -  27    positive percentage -  32\n",
      "carboxylic_acid                roc -  61    mse -  27    positive percentage -  14\n",
      "nitrogen_bearing_compound      roc -  71    mse -  17    positive percentage -  11\n",
      "chlorine_bearing_compound      roc -  48    mse -  7    positive percentage -  2\n",
      "sulfur_bearing_compound        roc -  60    mse -  10    positive percentage -  3\n",
      "alcohol                        roc -  55    mse -  10    positive percentage -  3\n",
      "other_oxygen_bearing_compound  roc -  67    mse -  6    positive percentage -  2\n",
      "mineral                        roc -  72    mse -  17    positive percentage -  14\n"
     ]
    }
   ],
   "source": [
    "# unscaled data using logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.33, random_state=42)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict_proba(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    print(cols.ljust(30,\" \"),\n",
    "        \"roc - \",math.ceil(roc_auc_score(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   mse - \",math.ceil(mean_squared_error(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   positive percentage - \", pos)\n",
    "\n",
    "# results are variable for different types\n",
    "# for random_state in [10 ,239,3,94023,234,342,234]:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.33, random_state=random_state)\n",
    "#     for i,cols in enumerate(classes):\n",
    "#         if (i==0):\n",
    "#             continue\n",
    "#         model = LogisticRegression(max_iter = 1000000)\n",
    "#         model.fit(X_train, y_train[:,i])\n",
    "#         preds = model.predict_proba(X_test)\n",
    "#         print(str(random_state).ljust(10,\" \"),cols.ljust(50,\" \"),roc_auc_score(y_test[:,i], preds[:, 1]))\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_np_minmax = scaler.fit_transform(X_np) \n",
    "test_np_minmax = scaler.transform(test_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       roc -  86    mse -  8    positive percentage -  9\n",
      "hydrocarbon                    roc -  87    mse -  14    positive percentage -  32\n",
      "carboxylic_acid                roc -  94    mse -  9    positive percentage -  14\n",
      "nitrogen_bearing_compound      roc -  93    mse -  8    positive percentage -  11\n",
      "chlorine_bearing_compound      roc -  98    mse -  3    positive percentage -  2\n",
      "sulfur_bearing_compound        roc -  90    mse -  3    positive percentage -  3\n",
      "alcohol                        roc -  93    mse -  3    positive percentage -  3\n",
      "other_oxygen_bearing_compound  roc -  90    mse -  3    positive percentage -  2\n",
      "mineral                        roc -  81    mse -  9    positive percentage -  14\n"
     ]
    }
   ],
   "source": [
    "#min max scaled input\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np_minmax, y_np, test_size=0.33, random_state=42)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict_proba(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    print(cols.ljust(30,\" \"),\n",
    "        \"roc - \",math.ceil(roc_auc_score(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   mse - \",math.ceil(mean_squared_error(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   positive percentage - \", pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X_np_std = std_scaler.fit_transform(X_np) \n",
    "test_np_std = std_scaler.transform(test_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       roc -  75    mse -  9    positive percentage -  9\n",
      "hydrocarbon                    roc -  83    mse -  18    positive percentage -  32\n",
      "carboxylic_acid                roc -  91    mse -  11    positive percentage -  14\n",
      "nitrogen_bearing_compound      roc -  91    mse -  10    positive percentage -  11\n",
      "chlorine_bearing_compound      roc -  98    mse -  3    positive percentage -  2\n",
      "sulfur_bearing_compound        roc -  83    mse -  3    positive percentage -  3\n",
      "alcohol                        roc -  92    mse -  4    positive percentage -  3\n",
      "other_oxygen_bearing_compound  roc -  86    mse -  4    positive percentage -  2\n",
      "mineral                        roc -  76    mse -  12    positive percentage -  14\n"
     ]
    }
   ],
   "source": [
    "# standard scaled input\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np_std, y_np, test_size=0.33, random_state=42)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict_proba(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    print(cols.ljust(30,\" \"),\n",
    "        \"roc - \",math.ceil(roc_auc_score(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   mse - \",math.ceil(mean_squared_error(y_test[:,i], preds[:, 1])*100),\n",
    "        \"   positive percentage - \", pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = \"\"\"               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.90      1.00      0.95       239\n",
    "         1.0       \"\"\"\n",
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       positive accuarcy 0.40\n",
      "hydrocarbon                    positive accuarcy 0.77\n",
      "carboxylic_acid                positive accuarcy 0.53\n",
      "nitrogen_bearing_compound      positive accuarcy 0.44\n",
      "chlorine_bearing_compound      positive accuarcy 0.00\n",
      "sulfur_bearing_compound        positive accuarcy 0.50\n",
      "alcohol                        positive accuarcy 1.00\n",
      "other_oxygen_bearing_compound  positive accuarcy 1.00\n",
      "mineral                        positive accuarcy 0.79\n"
     ]
    }
   ],
   "source": [
    "# for low positive compunds the algorithm performs worst and result is highly variable with random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np_minmax, y_np, test_size=0.33, random_state=43)\n",
    "for i,cols in enumerate(classes):\n",
    "    model = LogisticRegression(max_iter = 1000000)\n",
    "    model.fit(X_train, y_train[:,i])\n",
    "    preds = model.predict(X_test)\n",
    "    pos = int(100*y_np[:,i].sum()/809)\n",
    "    # print(cols,'\\n', classification_report(y_test[:,i], preds))\n",
    "    print(cols.ljust(30,\" \"),'positive accuarcy', classification_report(y_test[:,i], preds,zero_division=True)[len(ts)-1:len(ts)+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       positive accuarcy 0.38       total positive  9\n",
      "aromatic                       positive accuarcy 0.62       total positive  9\n",
      "aromatic                       positive accuarcy 0.30       total positive  9\n",
      "aromatic                       positive accuarcy 0.80       total positive  9\n",
      "aromatic                       positive accuarcy 0.67       total positive  9\n",
      "aromatic                       positive accuarcy 0.40       total positive  9\n",
      "aromatic                       positive accuarcy 0.80       total positive  9\n",
      "aromatic                       positive accuarcy 0.33       total positive  9\n",
      "aromatic                       positive accuarcy 0.50       total positive  9\n",
      "aromatic                       positive accuarcy 0.44       total positive  9\n",
      "aromatic                       positive accuarcy 0.44       total positive  9\n",
      "aromatic                       positive accuarcy 0.62       total positive  9\n",
      "aromatic                       positive accuarcy 0.75       total positive  9\n",
      "aromatic                       positive accuarcy 0.50       total positive  9\n"
     ]
    }
   ],
   "source": [
    "# result highly depends on random_state\n",
    "sel_cols = \"aromatic\"\n",
    "for rs in [231,3123,12,3,123,32,3,13,1000000,1010010,1232,32313,45362,562456]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np_minmax, y_np, test_size=0.33, random_state=rs)\n",
    "    for i,cols in enumerate(classes):\n",
    "        if (cols!=sel_cols):\n",
    "            continue\n",
    "        model = LogisticRegression(max_iter = 1000000)\n",
    "        model.fit(X_train, y_train[:,i])\n",
    "        preds = model.predict(X_test)\n",
    "        pos = int(100*y_np[:,i].sum()/809)\n",
    "        # print(cols,'\\n', classification_report(y_test[:,i], preds))\n",
    "        print(cols.ljust(30,\" \"),'positive accuarcy', classification_report(y_test[:,i], preds,zero_division=True)[len(ts)-1:len(ts)+3],\"      total positive \", pos)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aromatic                       positive accuarcy 0.25       total positive  9\n",
      "aromatic                       positive accuarcy 0.26       total positive  9\n",
      "aromatic                       positive accuarcy 0.33       total positive  9\n",
      "aromatic                       positive accuarcy 0.31       total positive  9\n",
      "aromatic                       positive accuarcy 0.23       total positive  9\n",
      "aromatic                       positive accuarcy 0.29       total positive  9\n",
      "aromatic                       positive accuarcy 0.31       total positive  9\n",
      "aromatic                       positive accuarcy 0.22       total positive  9\n",
      "aromatic                       positive accuarcy 0.25       total positive  9\n",
      "aromatic                       positive accuarcy 0.21       total positive  9\n",
      "aromatic                       positive accuarcy 0.20       total positive  9\n",
      "aromatic                       positive accuarcy 0.27       total positive  9\n",
      "aromatic                       positive accuarcy 0.23       total positive  9\n",
      "aromatic                       positive accuarcy 0.30       total positive  9\n"
     ]
    }
   ],
   "source": [
    "# gausian nb\n",
    "sel_cols = \"aromatic\"\n",
    "for rs in [231,3123,12,3,123,32,3,13,1000000,1010010,1232,32313,45362,562456]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np_minmax, y_np, test_size=0.33, random_state=rs)\n",
    "    for i,cols in enumerate(classes):\n",
    "        if (cols!=sel_cols):\n",
    "            continue\n",
    "        model = GaussianNB()\n",
    "        model.fit(X_train, y_train[:,i])\n",
    "        preds = model.predict(X_test)\n",
    "        pos = int(100*y_np[:,i].sum()/809)\n",
    "        # print(cols,'\\n', classification_report(y_test[:,i], preds))\n",
    "        print(cols.ljust(30,\" \"),'positive accuarcy', classification_report(y_test[:,i], preds,zero_division=True)[len(ts)-1:len(ts)+3],\"      total positive \", pos)\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since gausianNB depends on probability accuracy is worst,\n",
    "\n",
    "This is because the scaling and feature extraction are not efficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
